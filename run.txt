pip install --upgrade "transformers>=4.45.0" "accelerate>=0.34.0" \
  "peft>=0.11.1" "qwen-vl-utils>=0.0.8" "timm>=0.9.16" \
  "einops" "safetensors" "huggingface-hub>=0.24" "sentencepiece" "protobuf"









###################################


# Start a fresh terminal, then:
pip uninstall -y accelerate transformers peft timm qwen-vl-utils protobuf

# Install PyTorch + CUDA 12.1 wheels
pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cu121 \
  torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1

# Reinstall the rest (these versions work well with Qwen2.5-VL)
pip install --no-cache-dir \
  "transformers==4.55.4" "accelerate==1.10.0" "peft==0.17.1" \
  "timm==1.0.19" "qwen-vl-utils>=0.0.11" "einops" \
  "huggingface-hub>=0.24" "sentencepiece" "safetensors" "protobuf<5"


####################################


env -u LD_LIBRARY_PATH python tyuta.py

##########################################
##########################################
##########################################
##########################################
##########################################
##########################################
##########################################



best:



# 0) (you already did this) make sure we don't drag in system CUDA
unset LD_LIBRARY_PATH

# 1) Clean any older torch/transformers stack
pip uninstall -y torch torchvision torchaudio transformers accelerate peft timm tokenizers \
  qwen-vl-utils huggingface-hub safetensors sentencepiece protobuf 2>/dev/null || true
pip cache purge

# 2) Install a known-good stack (CUDA 12.1 wheels + recent Transformers)
pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cu121 \
  torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1

pip install --no-cache-dir \
  "transformers==4.55.4" \
  "accelerate==1.10.0" \
  "peft==0.17.1" \
  "timm==1.0.19" \
  "qwen-vl-utils>=0.0.11" \
  "tokenizers==0.21.4" \
  "safetensors>=0.6.2" \
  "huggingface-hub>=0.34.0" \
  "sentencepiece>=0.2.1" \
  "protobuf<5"  # keeps TensorFlow/W&B happy


pip install -U hf_transfer

pip uninstall -y deepspeed



env -u LD_LIBRARY_PATH \
  TRANSFORMERS_NO_TF=1 \
  TF_CPP_MIN_LOG_LEVEL=3 \
  HF_HUB_ENABLE_HF_TRANSFER=1 \
  python tyuta.py