pip install --upgrade "transformers>=4.45.0" "accelerate>=0.34.0" \
  "peft>=0.11.1" "qwen-vl-utils>=0.0.8" "timm>=0.9.16" \
  "einops" "safetensors" "huggingface-hub>=0.24" "sentencepiece" "protobuf"


##########################################
##########################################
##########################################
##########################################
##########################################
##########################################
##########################################



best:



# 0) (you already did this) make sure we don't drag in system CUDA
unset LD_LIBRARY_PATH

# 1) Clean any older torch/transformers stack
pip uninstall -y torch torchvision torchaudio transformers accelerate peft timm tokenizers \
  qwen-vl-utils huggingface-hub safetensors sentencepiece protobuf 2>/dev/null || true
pip cache purge

# 2) Install a known-good stack (CUDA 12.1 wheels + recent Transformers)
pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cu121 \
  torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1

pip install --no-cache-dir \
  "transformers==4.55.4" \
  "accelerate==1.10.0" \
  "peft==0.17.1" \
  "timm==1.0.19" \
  "qwen-vl-utils>=0.0.11" \
  "tokenizers==0.21.4" \
  "safetensors>=0.6.2" \
  "huggingface-hub>=0.34.0" \
  "sentencepiece>=0.2.1" \
  "protobuf<5"  # keeps TensorFlow/W&B happy


pip install -U hf_transfer

pip uninstall -y deepspeed



env -u LD_LIBRARY_PATH \
  TRANSFORMERS_NO_TF=1 \
  TF_CPP_MIN_LOG_LEVEL=3 \
  HF_HUB_ENABLE_HF_TRANSFER=1 \
  python train_qwen.py




for resume checkpoint:

# inside the notebook terminal
pip uninstall -y torch torchvision torchaudio xformers 2>/dev/null || true

# Install CUDA 12.4 wheels (bring their own CUDA)
pip install --upgrade --index-url https://download.pytorch.org/whl/cu124 \
  torch torchvision

# (optional) xformers for attention speedups compatible with torch 2.6
pip install --index-url https://download.pytorch.org/whl/cu124 xformers

# sanity check
python - <<'PY'
import torch; print("torch:", torch.__version__, "| CUDA ok:", torch.cuda.is_available(), "built:", torch.version.cuda)
PY



# clean out conflicting installs
pip uninstall -y bitsandbytes torch torchvision torchaudio xformers

# install PyTorch built for CUDA 12.1
pip install --index-url https://download.pytorch.org/whl/cu121 \
  torch==2.5.1 torchvision==0.20.1

# install bnb for cu121
pip install bitsandbytes==0.43.2

# (optional) xformers that matches this torch
pip install --index-url https://download.pytorch.org/whl/cu121 xformers


pip install -U --no-cache-dir \
  --index-url https://download.pytorch.org/whl/cu121 \
  "torchvision==0.20.1"





run eval only:

env -u LD_LIBRARY_PATH \
  TRANSFORMERS_NO_TF=1 \
  TF_CPP_MIN_LOG_LEVEL=3 \
  HF_HUB_ENABLE_HF_TRANSFER=1 \
  EVAL_ONLY=1 \
  python t.py